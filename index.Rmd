---
title:  | 
  | Statistical Evaluation of Prediction Models (SEPM.PUB): Numerical Experiments
  | 
pagetitle: SEPM.PUB
author: 
- Max Westphal <br> mwestphal@uni-bremen.de <br> https://github.com/maxwestphal <br> https://www.linkedin.com/in/maxwestphal/
date: "`r format(Sys.time(), '%d %B, %Y')`"
knit: (function(inputFile, encoding) { 
      out.dir <- file.path(dirname(inputFile), 'docs');
      dir.create(out.dir);
      rmarkdown::render(inputFile,
                        encoding=encoding, 
                        output_file=file.path(out.dir, 'index.html')) })
output: 
  rmdformats::readthedown:
    toc_depth: 3
    toc_float: true
    number_sections: true
    df_print: paged
    code_folding: hide
    css: styles.css
    keep_md: yes
editor_options: 
  markdown: 
    wrap: sentence
---

This R project (SEPM.PUB) contains a collection of research results and software in the context of model evaluation for machine-learned prediction models.

# Research projects

## **EOMPM**: Evaluation of multiple prediction models

Numerical experiments related to model evaluation in machine learning from the the publication **Westphal & Brannath (2019, SMMR)**.
A detailed description is provided at <https://github.com/maxwestphal/EOMPM>.

## **IMS**: Improving model selection in supervised ML

In this project, the complete machine learning and evaluation pipeline is emulated:

(a) **Training:** Prediction models are trained by different machine learning algorithms.
(b) **Validation:** A single or multiple models are chosen for an evaluation study.
(c) **Evaluation:** The selected models are tested for a sufficiently high performance.

The main novelty of our investigation is that the evaluation study is not restricted to only be conducted for a single (prespecified) model which is the usual recommendation in the machine learning literature.
This idea was introduced by **Westphal & Brannath (2019, SMMR)**.
As a consequence, statistical methods are needed to adjust for the introduced overoptimism due to the overlap of model selection and evaluation (based on the test data).
Several simulation studies have been conducted to assess the benefits and drawbacks of this approach, compare **Westphal & Brannath (2019, ICML)**.

-   **SIM/MLE_SIM_ACC**: Simulation study: Selection of prediction models, extensive results report at [MLE_SIM_ACC](https://maxwestphal.github.io/SEPM.PUB/MLE_SIM_ACC.html)

## **CPE**: Co-primary endpoint analysis

This is a follow-up of the **IMS** project.
Again, we investigate how to improve model evaluation studies in the supervised machine learning context.
Instead of looking at the overall accuracy of binary classifiers, we now focus on the so-called co-primary endpoint analysis.
Hereby, sensitivity and specificity are both assessed simultaneously, i.e. as co-primary endpoints.

-   **SIM/MLE_SIM_CPE**: Simulation study: Co-primary endpoint analysis of sensitivity and specificity
-   **RWD/CTG2**: Real world data example: Screening for abnormal fetal state

## **SIMPle**: Simultaneous inference for multiple proportions

Numerical experiments related to the publication **Westphal (2019)**: Assessment of coverage probability of multivariate Beta-Binomial credible regions under different prior distributions.

# R Packages

-   The [SEPM](https://github.com/maxwestphal/SEPM) package implements functions related to model selection, performance estimation and statistical testing for the purpose of model evaluation and comparison studies.
-   The [SEPM.MLE](https://github.com/maxwestphal/SEPM.MLE) package contains all functions for the simulations in the machine learning context, i.e. for generation of feature-label data, hyperparameter generation and model training and evaluation.
-   The [SEPM.SYN](https://github.com/maxwestphal/SEPM.SYN) package allows generation of synthetic multivariate binary data. -The [SIMPle](https://github.com/maxwestphal/SIMPle) package allows to conduct inference with a Bayesian multivariate beta-binomial model.

# References

-   [**Westphal & Brannath (2020, SMMR):**](https://journals.sagepub.com/doi/full/10.1177/0962280219854487) Westphal, M. and Brannath, W. Evaluation of multiple prediction models: a novel view on model selection and performance assessment. Statistical Methods in Medical Research, forthcoming 2019.
-   [**Westphal & Brannath (2019, ICML):**](http://proceedings.mlr.press/v97/westphal19a.html) Westphal, M. and Brannath, W. Improving Model Selection by Employing the Test Data. In Proceedings of the 36th International Conference on Machine Learning, Long Beach, California, PMLR 97, 2019.
-   [**Westphal (2019):**](https://arxiv.org/abs/1911.00098) Simultaneous Inference for Multiple Proportions: A Multivariate Beta-Binomial Model. arxiv preprint, 2019.
